kubectl create serviceaccount spark
kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default

1. :- To accesss the http://localhost:9090/browser go to kubernetes and go to namespace like s3a and click on secrets > 
      (Config And Storage >Secrets > s3a-env-configuration)
2. :- for access key go to http://localhost:9090/browser > user > Access keys > create access key and add in spark-submit code.
3. :-  ./spark-submit --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=l9clBhS80ZudADoDQnSS --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=5mU3bwzCDejg8aR3qgqwK0eVEsk8gUyxW0p0Cz6h --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://s3a-hl.s3a:9000 --conf spark.kubernetes.container.image=sonusukralia/spark:1.1 --conf spark.master=k8s://https://127.0.0.1:6443 local:///app/main1.py


Aad spark path :- nano ~/.bashrc
export PATH=$PATH:/usr/local/spark-3.5.2-bin-hadoop3/bin
export PATH=$PATH:/usr/bin/java
export JAVA_HOME=/usr/lib/jvm/java-1.17.0-openjdk-arm64


Copy these two file in jarrr folder
https://mvnrepository.com/artifact/org.bouncycastle/bcpkix-jdk18on/1.78
https://mvnrepository.com/artifact/org.bouncycastle/bcprov-jdk18on/1.78

Create DockerFile 
{
FROM apache/spark:3.5.1-scala2.12-java11-python3-r-ubuntu
USER root
COPY aws-java-sdk-bundle-1.12.276.jar /opt/spark/jars
COPY hadoop-aws-3.3.4.jar /opt/spark/jars
WORKDIR /app
COPY main.py .
COPY main1.py .
}

create Main1.py file 
{
from pyspark import SparkContext
from pyspark.sql import SparkSession

spark= SparkSession.builder.getOrCreate()


#def load_config(spark_context: SparkContext):
#    spark_context._jsc.hadoopConfiguration().set('fs.s3a.access.key', 'MWl3E0EHYzzdePYZdZ1b')
 #   spark_context._jsc.hadoopConfiguration().set('fs.s3a.secret.key', 'Mc0C49TpSl3SgnUMRuv6RumdzOoOcjMCRLL0WVRq')
 #   spark_context._jsc.hadoopConfiguration().set('fs.s3a.path.sytle.acess', 'true')
  #  spark_context._jsc.hadoopConfiguration().set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')
 #   spark_context._jsc.hadoopConfiguration().set('fs.s3a.endpoint', "http://s3a-hl.s3a:9000")
 #   spark_context._jsc.hadoopConfiguration().set('fs.s3a.connection.ssl.enabled', 'false')
    

#load_config(spark.SparkContext)

dataframe = spark.read.json('s3a://test/orders.json')

average = dataframe.agg({'amount':'avg'})

average.write.format("csv").option("header", "true").save(
    "s3a://test/json/")

average.show()
}

create main.py
{
import logging
import os

from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, LongType, DoubleType, StringType

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger("MinIOSparkJob")

spark = SparkSession.builder.getOrCreate()
#.config("spark.driver.extraJavaOptions", "-Djavax.net.debug=all -Djavax.net.ssl.trustStore=C:/DEVELOPMENT/spark/spark-3.5.1-bin-hadoop3/bin/truststore.jks -Djavax.net.ssl.trustStorePassword=admin12345$").config("spark.executor.extraJavaOptions", "-Djavax.net.debug=all -Djavax.net.ssl.trustStore=C:/DEVELOPMENT/spark/spark-3.5.1-bin-hadoop3/bin/truststore.jks -Djavax.net.ssl.trustStorePassword=admin12345$").getOrCreate()
#.config("spark.hadoop.fs.s3a.endpoint","https://127.0.0.1:9000").config("spark.hadoop.fs.s3a.access.key","XmnwPrE0powsLEQvLO2c").config("spark.hadoop.fs.s3a.secret.key","OwhMKq8jQQIzo6J0zoWE7bOlWoSGr2sfTZYuQhdb").config("spark.hadoop.fs.s3a.connection.ssl.enabled","true").config("spark.hadoop.fs.s3.endpoint","https://127.0.0.1:9000").config("spark.hadoop.fs.s3.awsAccessKeyId", "XmnwPrE0powsLEQvLO2c").config("spark.hadoop.fs.s3.awsSecretAccessKey","OwhMKq8jQQIzo6J0zoWE7bOlWoSGr2sfTZYuQhdb").config("spark.hadoop.fs.s3.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem").config("spark.hadoop.fs.s3a.aws.credentials.provider","org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider")


# def load_config(spark_context: SparkContext):
  #   spark_context._jsc.hadoopConfiguration().set("com.amazonaws.services.s3.disableGetObjectMD5Validation", "true")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3.endpoint", "https://127.0.0.1:9000")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3.awsAccessKeyId", "XmnwPrE0powsLEQvLO2c")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3.awsSecretAccessKey",
    #                                              "OwhMKq8jQQIzo6J0zoWE7bOlWoSGr2sfTZYuQhdb")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
 #    spark_context._jsc.hadoopConfiguration().set("fs.s3a.access.key", "XmnwPrE0powsLEQvLO2c")
 #    spark_context._jsc.hadoopConfiguration().set("fs.s3a.secret.key",
    #                                              "OwhMKq8jQQIzo6J0zoWE7bOlWoSGr2sfTZYuQhdb")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.endpoint", "https://127.0.0.1:9000")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3a.ssl.enabled", "true")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3a.ssl.keystore.location", "C:/DEVELOPMENT/spark/spark-3.5.1-bin-hadoop3/bin/truststore.jks")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.ssl.keystore.password", "admin12345$")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3a.ssl.truststore.location", "C:/DEVELOPMENT/spark/spark-3.5.1-bin-hadoop3/bin/truststore.jks")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.ssl.truststore.password", "admin12345$")
  #   spark_context._jsc.hadoopConfiguration().set("fs.s3a.connection.ssl.enabled", "true")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.path.style.access", "true")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.attempts.maximum", "1")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.connection.establish.timeout", "5000")
   #  spark_context._jsc.hadoopConfiguration().set("fs.s3a.connection.timeout", "5000")


# load_config(spark.sparkContext)

# Define schema for NYC Taxi Data
schema = StructType([
    StructField('VendorID', LongType(), True),
    StructField('tpep_pickup_datetime', StringType(), True),
    StructField('tpep_dropoff_datetime', StringType(), True),
    StructField('passenger_count', DoubleType(), True),
    StructField('trip_distance', DoubleType(), True),
    StructField('RatecodeID', DoubleType(), True),
    StructField('store_and_fwd_flag', StringType(), True),
    StructField('PULocationID', LongType(), True),
    StructField('DOLocationID', LongType(), True),
    StructField('payment_type', LongType(), True),
    StructField('fare_amount', DoubleType(), True),
    StructField('extra', DoubleType(), True),
    StructField('mta_tax', DoubleType(), True),
    StructField('tip_amount', DoubleType(), True),
    StructField('tolls_amount', DoubleType(), True),
    StructField('improvement_surcharge', DoubleType(), True),
    StructField('total_amount', DoubleType(), True)])

# Read CSV file from MinIO
df = spark.read.option("header", "true").schema(schema).csv(
    "s3a://test/taxi-data.csv")
# Filter dataframe based on passenger_count greater than 3
large_passengers_df = df.filter(df.passenger_count > 3)

total_rows_count = df.count()
filtered_rows_count = large_passengers_df.count()
# File Output Committer is used to write the output to the destination (Not recommended for Production)
large_passengers_df.write.format("csv").option("header", "true").save(
    "s3a://test/taxi-small/")

logger.info(f"Total Rows for NYC Taxi Data: {total_rows_count}")
logger.info(f"Total Rows for Passenger Count > 6: {filtered_rows_count}")

}


Add mvnrepositroy to spark jars folder

https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-aws/3.3.4
https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-bundle

https://mvnrepository.com/artifact/org.bouncycastle/bcpkix-jdk18on/1.78
https://mvnrepository.com/artifact/org.bouncycastle/bcprov-jdk18on/1.78







From
https://github.com/arunsrajan/tutorial/blob/main/sparkminio/commands.txt

minikube start -p minio --cpus 12 --memory 12g --mount=true --mount-string=C:\DEVELOPMENT\minio:/minio --subnet=192.168.89.0/24
Operator Hub Installation
--------------------------

kubectl create -f https://raw.githubusercontent.com/operator-framework/operator-lifecycle-manager/master/deploy/upstream/quickstart/crds.yaml
kubectl create -f https://raw.githubusercontent.com/operator-framework/operator-lifecycle-manager/master/deploy/upstream/quickstart/olm.yaml
minio installation
-------------------
kubectl create -f https://operatorhub.io/install/minio-operator.yaml


Operator Hub helm
------------------
helm repo add minio-operator https://operator.min.io
helm search repo minio-operator

helm install --namespace minio-operator --create-namespace minio-operator minio-operator/operator

Go To Minio Operator Pod
------------------------
cat /var/run/secrets/kubernetes.io/serviceaccount/token
Token: eyJhbGciOiJSUzI1NiIsImtpZCI6InVwUkFsRS1wMEplQ2lrX21fUWpLUzFsbGJfeXRUVkoxaVFjaG9UN1JnTmMifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzU0NzM5MTM2LCJpYXQiOjE3MjMyMDMxMzYsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJvcGVyYXRvcnMiLCJwb2QiOnsibmFtZSI6Im1pbmlvLW9wZXJhdG9yLTc0NmQ1YmM2ODktMmx4eHoiLCJ1aWQiOiI2MzFjOTE4OC1kZWEwLTRjMGQtYjRiOC1hODc1OGFhYTNiNTkifSwic2VydmljZWFjY291bnQiOnsibmFtZSI6Im1pbmlvLW9wZXJhdG9yIiwidWlkIjoiZGQ1Y2ZlMDAtOTlmMy00ZmYzLWJmODYtMDZlYmRhMzAzN2ViIn0sIndhcm5hZnRlciI6MTcyMzIwNjc0M30sIm5iZiI6MTcyMzIwMzEzNiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om9wZXJhdG9yczptaW5pby1vcGVyYXRvciJ9.Rk8rBcT0a2pBJQTyE20pmoGw9FAjDjQypbPXnkQeWkjqCoaDpvJPJaWjGLXrxZMKgdfwhfa-MsbM1BoZfOc5oZrGkYQRftdU9ugkdZlEqtk4nSRYMOMy_LMZSjk_xaSgyIN5a5d3H1kGCw1gF5BMRVdwE0Ng7TCjrPExLlSpz-PmV1czd1bC6GqG8Fyl_wgEIPPCpV4vgtILqkRwkfuqln7Lox6TCHRVSJFscpyvhQerxpgm2MwAuCg6EK2BHGbJuu0D7-IismnSKSxzX2Bu2pKtaKbQaZHVbERmAyeDq1ZonoTOkh2qqIlUaOLpRGHcNM1oFTnLkH751P_3nm6SSg
kubectl port-forward svc/console -n operators 9091:9090

kubectl create namespace minio-tenant

Tenant
------
curl -sLo values.yaml https://raw.githubusercontent.com/minio/operator/master/helm/tenant/values.yaml

helm upgrade --install --namespace minio-tenant --create-namespace --values miniovalues.yaml minio minio-operator/tenant

helm delete --namespace minio-tenant minio minio-operator/tenant


kubectl port-forward svc/myminio-console -n minio-tenant 9443:9443
kubectl port-forward svc/myminio-hl -n minio-tenant 9000:9000

minio
minio123

access key: xRUhzzp30azdYcB3RC1Z

access secret : iVfmUyeQzgQ2yugaiYT3pKg5FSKiz17pRFqdzsIj



aws s3 ls --region us-east-1 --endpoint https://127.0.0.1:9443 s3://test/ --no-verify-ssl


In Code
keytool -import -file public.crt -alias minio -keystore truststore.jks -storepass admin12345$


(AWS_ACCESS_KEY_ID (or AWS_ACCESS_KEY) and AWS_SECRET_KEY (or AWS_SECRET_ACCESS_KEY))


set AWS_ACCESS_KEY=xRUhzzp30azdYcB3RC1Z
set AWS_SECRET_ACCESS_KEY=iVfmUyeQzgQ2yugaiYT3pKg5FSKiz17pRFqdzsIj
set AWS_ACCESS_KEY_ID=xRUhzzp30azdYcB3RC1Z
set AWS_SECRET_KEY=iVfmUyeQzgQ2yugaiYT3pKg5FSKiz17pRFqdzsIj

Running Spark Kubernetes minio s3 bucket
----------------------------------------
kubectl create serviceaccount spark
kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
spark-submit.cmd --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=xRUhzzp30azdYcB3RC1Z --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=iVfmUyeQzgQ2yugaiYT3pKg5FSKiz17pRFqdzsIj --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://minio-hl.minio-tenant:9000 --conf spark.kubernetes.container.image=arunsrajan/spark:3.5.1 --conf spark.master=k8s://https://127.0.0.1:56484 local:///app/main.py




docker build -t arunsrajan/spark:3.5.1 .
docker push arunsrajan/spark:3.5.1






